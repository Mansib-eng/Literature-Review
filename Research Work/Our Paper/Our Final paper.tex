\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{longtable}
\usepackage{xcolor}
\usepackage{soulutf8}  % for highlighting and utf8-safe \hl
\usepackage{microtype} % better justification
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{tcolorbox} % for abstract box
\usepackage{colortbl}  % for row colors in tables
\usepackage{natbib}    % for \citealp (author-year, no brackets)

\geometry{margin=1in}

% Hyperref options for colored links and better pdf metadata
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=cyan,
    citecolor=blue,
    pdftitle={AI-Powered Methods for Assessing Attention and Focus},
    pdfauthor={},
    pdfstartview=FitH
}

% Colored section titles
\titleformat{\section}{\large\bfseries\color{teal}}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\normalsize\bfseries\color{teal}}{\thesubsection.}{0.5em}{}

% Improved list spacing
\setlist[itemize]{noitemsep, topsep=0pt, leftmargin=*, label=\textbullet}

% Fancy footer with page numbers centered
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}

% Table row coloring for better readability
\definecolor{lightgray}{gray}{0.9}

% tcolorbox for abstract
\newtcolorbox{abstractbox}{
  colback=gray!10!white,
  colframe=gray!50!black,
  boxrule=0.5pt,
  left=6pt,
  right=6pt,
  top=6pt,
  bottom=6pt,
  sharp corners,
  breakable
}

% Custom caption colors
\captionsetup{
  labelfont={bf, color=teal},
  textfont=it
}

% Make percent signs easy to type by defining \pct command
\newcommand{\pct}{\%}

\title{A Systematic Review on AI-Powered Methods for Assessing Attention and Focus in the Digital Age}
\author{}
\date{}

\begin{document}

\maketitle

\begin{abstractbox}
In today's world, our attention and focus are constantly broken due to regular interaction with technology. In our daily life, we spend quite some time with our smartphones, computers, and other devices. Due to the increase in screen time, our thought process has suffered greatly. With that in mind, it was obvious to realize the need for intelligent systems capable of monitoring, assessing, and increasing attention and focus. Artificial Intelligence or AI, particularly machine learning and deep learning models, has shown great promise in automating the detection and evaluation of mental health issues such as attention and focus. This review paper examines the status of AI-powered methods for assessing attention and focus in digital environments. We followed PRISMA guidelines to identify and filter relevant literature across five major databases, ultimately narrowing it down to 19 highly matched papers. Our systematic literature review focuses on the AI-powered techniques, common datasets used, the evaluation metrics used, and applications such as online learning, mobile usage, and social media, and their role in assessing attention and focus. From our work, the key findings reveal that most of the AI-powered methodologies have a great reliance on supervised learning algorithms and techniques. Our paper ends with mentioning the current challenges and recommending directions for future research.
\end{abstractbox}

\section{Introduction}
Attention and focus are the two greatest components of human psychology. They are most important in learning, understanding, productivity in daily life, and mental health. However, the frequent use of technology such as smartphones and social media platforms in the online education system has introduced new challenges for mental health issues, especially with learning, keeping up attention, and focus while doing so.

Recent advancements in machine learning, deep learning, and other AI techniques, along with cognitive science, offer a variety of techniques for modeling human attention through behavioral, physiological, and interaction-based signals.

Currently, these systems are being deployed in educational environments, digital well-being tools, human-computer interaction systems, and mental health diagnostics. But, despite the growing interest in research in this domain, there is a limited combination of findings regarding the specific AI methods used, their effectiveness, and the contexts in which they are applied. And that is the main object of our review paper.

This systematic literature review aims to critically analyze the studies that use AI-powered approaches for assessing attention and focus in digital contexts.

\section{Methodology}
Our review process follows the systematic methodology described in the PRISMA framework. The process involved designing a search term, multiple database queries, filtering papers, and then manual screening, as mentioned below. We used a very intelligent search technique, the detailed search strategy table provided below. This was specifically designed to cover a wide range of relevant domains.

\subsection{Search Strategy and Data Sources} 
We used a comprehensive search strategy. We formulated this strategy using a combination of terms related to AI techniques and attention, and focus. The search was conducted across five major academic databases: IEEE Xplore, ACM Digital Library, ScienceDirect, Google Scholar, and PubMed. Our search finally resulted in an initial pool of 346 papers. These areas included AI/ML core terms, human-computer interaction, or HCI. We also considered non-AI tools, digital distraction, education, and mental health. \\

\begin{table}[H]
\caption{Search Log Table}
\rowcolors{2}{lightgray}{white}
\begin{tabular}{|p{0.30\textwidth}|p{0.60\textwidth}|p{0.10\textwidth}|}
\hline
\textbf{Main Area} & \textbf{Search Terms} & \textbf{Paper Count} \\
\hline
\textbf{AI/ML-focused (Generic)} & "AI-based attention assessment", "Artificial Intelligence for attention and focus", "Machine learning attention tracking", "Deep learning for cognitive focus", "AI models for focus detection", "Intelligent systems for attention measurement", "Neural networks for attention analysis", "Transformer models for attention estimation", "AI-based attention prediction" & 70 \\
\hline
\textbf{AI/ML + Human Factors} & "AI in cognitive psychology", "Machine learning for cognitive load estimation", "AI-based focus analysis in human-computer interaction", "AI and attention span detection", "AI-based focus assessment in education", "ML models for attention monitoring in digital learning" & 32 \\
\hline
\textbf{Computer Science + Non-AI Technical Methods} & "Software tools for attention tracking", "Digital methods for cognitive load measurement", "Sensor-based focus detection", "Non-AI attention analysis", "Computer vision attention measurement (non-AI)", "EEG-based attention analysis (non-ML)", "Web-based cognitive focus tools", "Technology-supported attention evaluation" & 28 \\
\hline
\textbf{AI + Technology Usage (Social Media, Apps, etc.)} & "AI for attention span analysis on social media", "AI attention detection in app usage", "AI-based digital well-being models", "Machine learning for smartphone distraction detection", "AI tracking of multitasking impact", "AI-based behavioral data for attention", "AI + attention analysis + mobile data" & 24 \\
\hline
\textbf{Tech Usage Only (No AI)} & "Impact of smartphone use on attention", "Attention problems in digital age", "Technology and attention span issues", "Screen time and focus disruption", "Cognitive load due to digital technology", "Focus-related digital distraction", "Attention span in tech-driven environment" & 63 \\
\hline
\textbf{Education / Learning Environments + AI} & "AI-powered focus tracking in online learning", "AI-based attention monitoring in e-learning", "Intelligent tutoring systems and focus", "ML-based student engagement prediction", "AI for assessing attention in MOOCs" & 66 \\
\hline
\textbf{Healthcare / Mental Health + AI} & "AI detection of ADHD", "Machine learning for attention disorders", "AI models for neurodivergent focus patterns", "AI-powered assessment of attention deficits", "AI + cognitive load in mental health" & 63 \\
\hline
\end{tabular}
\end{table}

\subsection{PRISMA Steps}
\textbf{Identification} \\ 
In the identification phase, we gathered from seven CSV files, each CSV file contained results from literature searches conducted over the five academic databases: IEEE Xplore, ACM Digital Library, ScienceDirect, Google Scholar, and PubMed. We performed the searches by combining keywords related to "Artificial Intelligence", "Machine Learning", and "Attention/Focus". This stage resulted in 346 initial records. \\ \\
\textbf{Deduplication (DOI Link)} \\ 
To eliminate duplicate studies, an automated Python program was used to compare the "DOI link" field across all records. As each DOI uniquely identifies a publication, this method reliably removes redundant entries. This step excluded 6 duplicate records, reducing the dataset to 340 unique papers. \\ \\
\textbf{Deduplication (Paper Title)} \\ 
Some duplicate papers did not share an identical DOI link due to formatting issues or missing values. To address this, we used the same Python program[20] to normalize the "Paper Title" field (by converting to lowercase, stripping whitespace, and standardizing spacing). In this step, we removed an additional 3 records and resulting in a final dataset of 337 unique papers. \\ \\ \\
\textbf{AI, ML, DL Relevance Filter} \\ 
In this stage, we wrote another Python program[21] to keep only the papers whose titles mentioned AI-related terms. 
\begin{itemize}
    \item Firstly, we converted all characters to lowercase.
    \item Then we replaced all the hyphens (-) and slashes (/) with spaces too, so that compound words like "AI-based" and "AI/ML" become "AI-based" and "ai ml".
\end{itemize}

The script then matched cleaned titles against a list of AI-related keywords using regex. Only titles containing terms like "\textbf{ai}", "\textbf{artificial intelligence}", "\textbf{ml}", "\textbf{machine learning}", "\textbf{dl}", or "\textbf{deep learning}" were retained. After this filtering step, the dataset was reduced from 337 to 140 papers.
 \\ \\
\textbf{Attention \& Mental Health Filter} \\ 
In this stage, we wrote another Python program[22] to keep only those papers whose titles aligned with the core of our research objective: \textbf{AI-powered methods for assessing attention and mental focus}. To ensure perfect matching, the program used a curated list of over 50 keywords related to \textbf{attention}, \textbf{cognitive function}, and \textbf{mental health} conditions such as "attention-span", "cognitive-load", "ADHD", and "working memory". In this step, the paper dataset was reduced to 102 papers. \\ \\
\textbf{AI-Driven Method Filter} \\ 
In this stage, we again used a Python script[23]  to further refine the dataset by \textbf{including only those papers} whose titles mentioned AI-driven methodological terms. To achieve this, the script uses a list of AI method keywords, including terms such as "detection", "assessment", "modeling", "learning", "prediction", and "classification". Regex with word boundary matching ensured accurate filtering without capturing partial words. As a result, 84 papers were included in the final dataset. \\ \\
\textbf{Contextual/Digital Setting Filter} \\ 
In this step, we used another Python script[24] to keep only those papers whose titles mentioned a digital environment relevant to AI-powered attention research. The script matched the cleaned titles against a list of keywords representing digital platforms, educational settings, such as "digital", "learning", "social media", "application", "user behavior", and "human factors". The process reduced the dataset from 84 to \textbf{73 papers}. \\ \\
\textbf{Manual Title Screening} \\ 
In this stage, we manually checked the 73 papers that passed all previous automated program filters. We carefully examined the title of each paper to determine whether it directly aligned with our research. \textbf{AI-powered methods for assessing attention and focus in digital environments}. Papers that were off-topic, too general, focused on unrelated AI applications, or lacked a clear connection to attention/focus were excluded based on expert judgement. As a result, the dataset was reduced to a final set of \textbf{38 papers}. \\ \\
\textbf{Abstract Screening} \\ 
In this stage, we manually reviewed the abstracts of the remaining 38 papers to determine their \textbf{high relevance} to the research topic. 

We used the following major points to make the judgment:
\begin{itemize}
    \item \textbf{AI/ML techniques} applied to \textbf{attention or focus assessment}
    \item Use of relevant \textbf{datasets and metrics}
    \item Evidence of \textbf{model effectiveness}
    \item Discussion of \textbf{technical challenges}
    \item Suggestions for \textbf{future directions}
\end{itemize}

Papers that clearly addressed these points in digital environments, such as online learning, smart classrooms, and real-time monitoring systems, were kept. The process resulted in \textbf{25 papers}. These are the papers that are mostly aligned with our research. \\ \\
\textbf{PDF Retrieval} \\ 
Out of the 25 papers that we selected after abstract screening, we found full-text PDFs for 19 papers. These are the final \textbf{19 papers}.\\ \\
\begin{table}[H]
\centering
\caption{PRISMA Log Table}
\rowcolors{2}{lightgray}{white}
\begin{tabular}{|p{0.22\textwidth}|p{0.42\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|}
\hline
\textbf{Stage} & \textbf{Criteria} & \textbf{Included / Excluded} & \textbf{Paper Remaining Count} \\
\hline
Identification & Records identified using search terms across 7 CSV files from 5 databases & Included & 346 \\
\hline
Deduplication (DOI link) & Removed exact duplicates based on 'DOI link' field using Python script & Excluded & 340 \\
\hline
Deduplication (Title) & Removed additional duplicates using normalized 'Paper Title' with Python-based string cleaning and matching & Excluded & 337 \\
\hline
AI, ML, DL Relevance Filter & Filtered titles using Python to retain only papers mentioning AI, ML, or DL (handling hyphens, slashes, punctuation) & Excluded & 140 \\
\hline
Attention \& Mental Health Filter & Filtered papers using Python to include only those mentioning attention, focus, cognitive load, or mental health & Excluded & 102 \\
\hline
AI-Driven Method Filter & Included only papers with AI-method terms (e.g., detection, prediction, modeling) in title using Python & Included & 84 \\
\hline
Contextual/Digital Setting Filter & Included only papers with digital or behavioral context terms (e.g., learning, app, social media, human factors) & Included & 73 \\
\hline
Manual Title Screening & Manually excluded irrelevant papers based on subjective review of titles and topic fit & Excluded & 38 \\
\hline
Abstract Screening & Retained only highly relevant papers after manual review of abstracts against SLR criteria and RQs & Included & 25 \\
\hline
PDF Retrieval & Successfully retrieved full-text PDF versions of selected papers for in-depth review & Included & 19 \\
\hline
\end{tabular}
\end{table}

\vspace{50em}
\captionof{figure}{PRISMA-Style Systematic Review Flowchart}
\begin{figure}[H]
\centering
\includegraphics[width=.25\textwidth]{Prisma.png}
\end{figure}


\vspace{50em}
\section{Data Extraction}
This table summarizes key extracted information from 19 reviewed research papers related to AI based attention monitoring, focus, and engagement detection.
\rowcolors{2}{lightgray}{white}
\begin{longtable}{|p{0.03\textwidth}|p{0.15\textwidth}|p{0.13\textwidth}|p{0.13\textwidth}|p{0.10\textwidth}|p{0.13\textwidth}|p{0.13\textwidth}|p{0.13\textwidth}|}
\hline
\textbf{No.} & \textbf{Paper Title} & \textbf{AI Techniques Used} & \textbf{Dataset Description} & \textbf{Evaluation Metrics} & \textbf{Reported Accuracy / Effectiveness} & \textbf{Key Challenges Noted} & \textbf{Future Directions Suggested} \\
\hline
\endfirsthead
\hline
\textbf{No.} & \textbf{Paper Title} & \textbf{AI Techniques Used} & \textbf{Dataset Description} & \textbf{Evaluation Metrics} & \textbf{Reported Accuracy / Effectiveness} & \textbf{Key Challenges Noted} & \textbf{Future Directions Suggested} \\
\hline
\endhead
1 & Student’s Attention Monitoring System in Learning Environments based on Artificial Intelligence [1] & YOLO v3, Deep Learning, Computer Vision & Facial expressions, head pose, motion data from video conferences & Accuracy, Attention \%, Facial Expression Detection & High real-time monitoring accuracy & Real-time performance, virtual learning limitations, facial expression analysis & Multi-modal learning, real-time behavior analysis, virtual engagement \\
\hline
2 & Predicting Level of Visual Focus of Human’s Attention Using ML Approaches [2] & Logistic Regression, SVM, Decision Tree, KNN, AdaBoost, MLP, Extra Tree, Voting Classifier & Survey reports + eyeball tracking & Accuracy & LR: 96\%, Voting: 95\% & Small sample, self-report bias, simple hardware & Larger diverse samples, personalization, real-time data \\
\hline
3 & Classification of EEG Signals for Cognitive Load Estimation Using DL Architectures [3] & SDAE+MLP, LSTM+MLP, SVM, KNN, LDA & EEG data (64-channel) at IIT Kharagpur & Accuracy & LSTM+MLP: 85.42\% & Small dataset, subject variability, denoising & Larger datasets, personalization, hybrid models \\
\hline
4 & Cognitive Load Estimation Using Hybrid Cluster-Based Unsupervised ML Technique [4] & Hybrid clustering, 1D CNN & 4-channel wearable EEG (Baseline \& Stroop test) & Accuracy, Homogeneity, ARI, SC & Accuracy: 93.2\%, ARI: 0.78 & Generalization, real-world application & Real-time estimation, low manual effort \\
\hline
5 & Early Detection of Preschool Children with ADHD Using AI \& Mobile Apps [5] & Mobile apps, AI tools, video analytics & Psychometric scales, behavioral data, app usage & DSM-5/ICD-10, clinical validation & Mobile apps effective for early detection & Subjectivity, comorbidity, over/under-diagnosis & Larger validation, explainable AI, early intervention \\
\hline
6 & TeacherEye: AI-Powered Monitoring System for Online Education [6] & DeepFace, VGG-Face, Dlib, MediaPipe, GPT-4 & Webcam video/audio, face images, speech clips & Recall, WER, Precision & Face ID: 100\%, Audio: 92.6\%, Cheating: 80\% & Privacy, false positives, sensory limits & On-device processing, GUI integration \\
\hline
7 & Students’ Attention Assessment in eLearning with ML [7] & Gabor, SVM, NBC, KNN, PCA, facial landmarks & CEW dataset (eye state), 32x32 pixel images & Classification Accuracy & Gabor+SVM: 93.1\% & Binary classification only, frontal face required & Blink detection, diverse attention features \\
\hline
8 & Real-Time Attention Monitoring with DL [8] & YOLOv5, DeepSORT & 5,701 action images + 35,000 emotion images & Precision, Recall, mAP@0.5, F1 & Action: 76\% mAP, Emotion: 87.7\% mAP & Small dataset, privacy & Multi-modal fusion, explainable AI \\
\hline
9 & Student-Engagement Detection in Classroom Using ML [9] & CATBoost, XGBoost, LightGBM & OULAD dataset (32,593 records) & Accuracy, F1, AUC-ROC & CATBoost: 92.23\%, AUC: 0.9626 & Class imbalance & Adaptive interventions \\
\hline
10 & Dyslexia Adaptive Learning Model: Engagement Prediction [10] & SVM, BoF, k-Means & 600 face images (30 students) & Accuracy & SVM Linear: 97.8\% & Small sample, occlusion & Integrate video \\
\hline
11 & ML in ADHD and Depression Mental Health Diagnosis: A Survey [11] & SVM, CNN, Random Forest & ADHD-200 (973), DAIC-WOZ (142) & Accuracy, AUC & ADHD: 99.58\%, Depression: 100\% (EEG) & Data imbalance & Multimodal datasets \\
\hline
12 & ML in ADHD: Neural Mechanism Analysis [12] & SVM, DNN, LASSO & ADHD-200, ABCD & AUC, Sensitivity & 60-90\% Accuracy & Small samples & Generative models \\
\hline
13 & Automatic Diagnosis of ADHD Using ML [13] & Decision Tree, Random Forest, SVM & NHS data (69 patients) & AUC & DT: 85.5\%, AUC: 0.871 & Overfitting & Fuzzy rule-based models \\
\hline
14 & Game Data Analysis for ADHD Assessment [14] & AdaBoost, JRip & Sifteo Cubes, 52 subjects & F-measure & 75-78\% Accuracy & Hardware limits & Neuroplasticity integration \\
\hline
15 & ADHD Detection Using Multimodal Physiological Data [15] & SVM, Random Forest & 76 adults & Accuracy & SVM: 81.6\% & No comorbidity control & Larger validations \\
\hline
16 & Autism Spectrum Disorder Assessment Using ML [16] & LSTM, CNN, SVM & Eye-tracking datasets & AUC & Up to 93.7\% (SVM) & Ecological validity & VR tool integration \\
\hline
17 & ML on Psychometric Questionnaires for ADHD [17] & 12+ ML techniques & 35–13,000 participants & AUC & AUC: 0.56–0.992 & Subjectivity & Multi-informant model \\
\hline
18 & ADHD Identification with Deep Learning [18] & BiLSTM, MVMD & 121-subject EEG data & ROC-AUC & Accuracy: 95.54\% & EEG artifacts & Real-time system \\
\hline
19 & ADHD Diagnosis Using SPECT with ML [19] & SVM, KNN & 236 brain scans & F-measure & Accuracy: 98\% & Class imbalance & Subtype classification \\
\hline
\end{longtable}

\section{Results}
This section represents an analysis of what we found from the 19 reviewed papers. We analyze the paper on the basis of some questions related to Artificial Intelligence techniques, datasets, evaluation metrics, effectiveness, challenges, and future directions in Artificial Intelligence based attention assessment.

\subsection{What Artificial Intelligence techniques are commonly used for assessing attention and focus in digital environments?}
From the reviewed papers, a large range of Artificial Intelligence techniques were used to assess attention and focus, advancements in machine learning, and deep learning. These methods were applied to different datasets, such as physiological signals (such as, \textbf{EEG}), behavioral data (such as, \textbf{facial expressions}, \textbf{eye-tracking}), and environmental factors (such as, \textbf{video data from classrooms}).

\begin{itemize}
    \item \textbf{Deep Learning Models}: Deep learning methods, especially Convolutional \textbf{Neural Networks (CNNs)} and \textbf{Long Short-Term Memory (LSTM)} networks, were frequently used for attention and focus detection tasks involving sequential or image data. As an example, \textbf{YOLOv3} and \textbf{YOLOv5} Papers~([\citealp{ref1}], [\citealp{ref8}]) were used to analyze real-time student behavior in classrooms and e-Learning environments. These models can have significant effectiveness in detecting attention by tracking facial expressions and body movements.
    \item \textbf{Support Vector Machines (SVM)}: \textbf{SVM} was another widely used method, especially for classification tasks involving \textbf{EEG} and \textbf{behavioral data}. SVM models were found to perform well in identifying attention-based patterns and cognitive states, especially in \textbf{ADHD} diagnosis and cognitive load estimation tasks Papers~([\citealp{ref11}], [\citealp{ref12}], [\citealp{ref19}]). Combining with methods like \textbf{Random Forest} or \textbf{Deep Neural Networks (DNNs)} the SVM classifiers can have high accuracy in detecting attention shifts.
    \item \textbf{Random Forest and Ensemble Methods}: \textbf{Random Forest}, \textbf{AdaBoost}, and \textbf{XGBoost} were used in various studies for tasks such as classifying attention in educational factors and diagnosing \textbf{ADHD}. These models provided robust results by combining multiple classifiers but small sample sizes cause overfitting Papers~([\citealp{ref2}], [\citealp{ref13}], [\citealp{ref15}]).
    \item \textbf{Behavioral and Physiological Data Integration}: An important section that the integration of multiple data types, such as \textbf{facial expression recognition (FER)}, \textbf{eye-tracking}, and \textbf{EEG data}. The integration of these features using machine learning techniques like \textbf{SVM} or \textbf{Deep Neural Networks (DNNs)} allowed for better prediction of attention levels Papers~([\citealp{ref7}], [\citealp{ref16}]). This combination of data types made the models stronger by balancing out the weaknesses.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{piechart.png}
\caption{Distribution of AI Techniques Used}
\end{figure}

\begin{table}[H]
\centering
\caption{AI Subfields and Techniques Summary}
\rowcolors{2}{lightgray}{white}
\begin{tabular}{|p{4.5cm}|p{6cm}|p{2cm}|p{4cm}|}
\hline
\textbf{AI Subfield} & \textbf{Techniques Used} & \textbf{Number of Papers} & \textbf{Paper Numbers} \\
\hline
Computer Vision & YOLO v3, Deep Learning, Computer Vision & 2 &  Papers~([\citealp{ref1}], [\citealp{ref8}]) \\
\hline
Machine Learning (ML) & Logistic Regression, SVM, Decision Tree, KNN, AdaBoost, MLP, Extra Tree Classifier, Voting Classifier & 7 &  Papers~([\citealp{ref2}], [\citealp{ref3}], [\citealp{ref7}], [\citealp{ref9}], [\citealp{ref10}], [\citealp{ref12}], [\citealp{ref13}]) \\
\hline
Deep Learning & SDAE + MLP, LSTM + MLP, 1D CNN, CNN, BiLSTM, DNN & 8 & Papers~([\citealp{ref3}], [\citealp{ref4}], [\citealp{ref6}], [\citealp{ref8}], [\citealp{ref11}], [\citealp{ref12}], [\citealp{ref18}], [\citealp{ref19}]) \\
\hline
Hybrid Models & Hybrid cluster-based unsupervised learning, 1D CNN & 1 & Paper~([\citealp{ref4}]) \\
\hline
Natural Language Processing (NLP) & Whisper API, GPT-4 & 1 & Paper~([\citealp{ref6}]) \\
\hline
Feature Extraction \& Recognition & DeepFace, VGG-Face, Dlib, EAR, MobileNet-SSD, MediaPipe Pose, FER & 1 & Paper~([\citealp{ref6}]) \\
\hline
Data Fusion/Multimodal & Multiple ML techniques (integrated analysis across modalities) & 1 & Paper~([\citealp{ref7}]) \\
\hline
Reinforcement Learning & None & 0 & - \\
\hline
\end{tabular}
\end{table}

\subsection{What datasets and evaluation metrics are used for Artificial Intelligence based attention assessment studies?}
The datasets and evaluation metrics used in the reviewed studies varied greatly, reflecting the differences in attention-related tasks. From diagnostic assessments of different datasets and metrics were used to monitoring attention in real-time classroom factors and attention disorders like ADHD. \\ \\
\textbf{Datasets:} A range of datasets was applied to assess attention and focus, with a focus on both behavioral data and physiological signals. \\ \\
\textbullet \textbf{EEG-based datasets} were most commonly used in the context of cognitive load and attention deficit detection.  For example, the \textbf{ADHD-200} dataset gave a large collection of EEG data for ADHD classification Papers~([\citealp{ref11}], [\citealp{ref19}]). Also, EEG data from wearable devices were used in real-time attention estimation tasks Papers~([\citealp{ref3}], [\citealp{ref4}]).  \\ \\
\textbullet \textbf{Eye-tracking datasets} were also common in attention studies, especially for analyzing visual attention in e-Learning and classroom environments. The \textbf{CEW dataset} and \textbf{OULAD dataset} gave data on eye states, facial expressions and pupil movements. Papers~([\citealp{ref7}], [\citealp{ref9}]).  \\ \\ \\
\textbullet \textbf{SPECT brain scans} were used in some studies to assess brain activity and its correlation with attention deficits Paper~([\citealp{ref19}]). These datasets used for understanding attention-related disorders in-depth.  \\ \\
\textbullet \textbf{Facial expression datasets} were generally useful in assessing attention in facial expressions were linked to students' engagement levels Papers~([\citealp{ref1}], [\citealp{ref9}]).  \\ \\

\textbf{Evaluation Metrics:} Several evaluation metrics were used to assess the effectiveness of Artificial Intelligence models in detecting attention shifts and disorders:  \\ \\
\textbullet \textbf{Accuracy} was the most common metric that is used to classifying attention levels in real-time systems Papers~([\citealp{ref1}], [\citealp{ref3}], [\citealp{ref8}]). \textbf{Deep Learning} and \textbf{SVM} models achieved high accuracy scores in various attention-related tasks.  \\ \\
\textbullet \textbf{Precision, Recall, and F1-Score} were commonly used to evaluate performance in imbalanced datasets, that in real-time applications where precision and recall are important for identifying both attention and distraction states Papers~([\citealp{ref2}], [\citealp{ref6}], [\citealp{ref9}]).  \\ \\
\textbullet \textbf{Area Under Curve (AUC)} was often used for ADHD detection and cognitive load estimation tasks. Those observed in studies with \textbf{SVM} Papers~([\citealp{ref11}], [\citealp{ref12}], [\citealp{ref19}]), which has High AUC values, demonstrated the ability of model that discriminates between different attention-related states effectively.  \\ \\
\textbullet \textbf{Homogeneity Score} and \textbf{Silhouette Coefficient} were used in unsupervised learning models to assess the quality of clustering in attention data Paper~([\citealp{ref4}])).  \\ 

\subsection{How effective are machine learning models in detecting shifts in attention?} 
The machine learning models demonstrated varying levels of effectiveness depending on the dataset used and the context of the task: \\ 

\textbullet \textbf{Real-Time Attention Monitoring:} It is used for monitoring attention in classroom and e-Learning environments, \textbf{Deep Learning} models such as \textbf{YOLOv3} and \textbf{YOLOv5} work brilliantly in real-time performance, detecting attention shifts with high accuracy Paper~([\citealp{ref8}]). These models were capable of processing video data to assess facial expressions and body movements, which are the main indicators of attention in educational settings. \\ \\ 
\textbullet \textbf{EEG and Cognitive Load Estimation:} Deep learning models like \textbf{SDAE + MLP} and \textbf{LSTM + MLP} achieved accuracies of up to \textbf{85.42\%} for detecting shifts in cognitive load and attention using EEG Paper~([\citealp{ref3}]). These models were effective in detecting subtle shifts in attention during tasks of varying difficulty and also highlighting their potential in cognitive workload management.  \\ \\
\textbullet \textbf{ADHD Detection:} \textbf{ADHD-200} and \textbf{SPECT brain scans} were highly effective in detecting attention deficits associated with \textbf{ADHD} that achieving accuracies of \textbf{up to 99.58\%} Papers~([\citealp{ref11}], [\citealp{ref19}]). All of these models used a combination of \textbf{SVM}, \textbf{Random Forest}, and \textbf{CNN} architectures to classify \textbf{ADHD} based on neuroimaging and physiological data.  \\ \\
\textbullet \textbf{Facial Expression and Eye-Tracking Models:} Models analyzing facial expressions and eye-tracking data in classroom settings demonstrated high performance that accuracies ranging \textbf{from 85\% to 93.1\%} Papers~([\citealp{ref7}], [\citealp{ref8}]). These models were especially effective at detecting attention shifts which is related to student engagement in educational contexts.  \\ 

\subsection{ What challenges and limitations exist in Artificial Intelligence powered attention assessment?}
Several challenges and limitations were identified across the reviewed studies: \\

\textbullet \textbf{Data-Related Issues:} Many studies suffered from \textbf{small sample sizes} Papers~([\citealp{ref3}], [\citealp{ref13}]). Also, \textbf{data imbalance} was a significant issue in datasets involving attention states, where low-attention states were often ignored Papers~([\citealp{ref9}], [\citealp{ref19}]). \\ \\ 
\textbullet \textbf{Overfitting:} Overfitting was a common issue in models trained on small or highly specific datasets. Overfitting led to reduced performance on unseen data Papers~([\citealp{ref6}], [\citealp{ref15}]).  \\ \\
\textbullet \textbf{Privacy and Ethical Concerns:} \textbf{Privacy and Ethical Concerns:} The use of \textbf{biometric data}, including facial expressions, EEG, and physiological measurements, raised concerns about privacy and ethical associations, especially when working with children Papers~([\citealp{ref6}], [\citealp{ref15}]).  \\ \\
\textbullet \textbf{Hardware Constraints:} \textbf{Hardware Constraints:} Many models required specialized equipment, such as \textbf{EEG headsets} and \textbf{eye-trackers}, which creates an issue in scalability in real-world applications. Developing models that are less reliant on expensive hardware was a key challenge Papers~([\citealp{ref8}], [\citealp{ref14}]). \\ 

\begin{table}[H]
\centering
\caption{Key Limitations Identified in Reviewed Papers}
\rowcolors{2}{lightgray}{white}
\begin{tabular}{|p{0.50\textwidth}|p{0.25\textwidth}|p{0.22\textwidth}|}
\hline
\textbf{Key Limitation} & \textbf{No. of Papers Addressing This Limitation} & \textbf{Papers} \\
\hline
Small sample size & 8 & Papers~([\citealp{ref2}], [\citealp{ref3}], [\citealp{ref4}], [\citealp{ref7}], [\citealp{ref10}], [\citealp{ref12}], [\citealp{ref14}], [\citealp{ref15}]) \\
\hline
Data imbalance & 3 & Papers~([\citealp{ref9}], [\citealp{ref11}], [\citealp{ref13}]) \\
\hline
Subject variability & 1 & Paper~([\citealp{ref3}]) \\
\hline
Privacy concerns & 2 & Papers~([\citealp{ref6}], [\citealp{ref8}]) \\
\hline
Overfitting risk & 1 & Paper~([\citealp{ref13}]) \\
\hline
Comorbidities and diagnosis accuracy & 2 & Papers~([\citealp{ref5}], [\citealp{ref15}]) \\
\hline
Limited feature sets (e.g., blink frequency, eye states) & 2 & Papers~([\citealp{ref7}], [\citealp{ref8}]) \\
\hline
Lack of ecological validity (real-world applicability) & 1 & Paper~([\citealp{ref16}]) \\
\hline
No control for confounding factors (e.g., comorbidities) & 1 & Paper~([\citealp{ref15}]) \\
\hline
\end{tabular}
\end{table}

\subsection{ What are the future research directions for Artificial Intelligence based attention analysis?} 

The studies identify several important future directions for advancing Artificial Intelligence based attention assessment: \\

\textbullet \textbf{Multimodal Approaches:} Combining multiple data types, such as \textbf{EEG}, \textbf{facial expressions}, and \textbf{eye-tracking}, was highlighted as a great direction for improving attention detection accuracy. Multimodal systems can decrease limitations of individual data types and create more robust models Papers~([\citealp{ref1}], [\citealp{ref7}], [\citealp{ref8}]). \\ 

\textbullet \textbf{Real-Time Systems and Scalability:} Future research should focus on developing \textbf{real-time attention monitoring systems} that can be used in dynamic environments such as classrooms or workplaces. Improving the scalability of Artificial Intelligence models for large usage, especially in large, diverse populations that can strengthen models Papers~([\citealp{ref6}], [\citealp{ref16}]). \\ 

\textbullet \textbf{Explainability and Transparency:} In modern days, Artificial Intelligence models become more integrated into clinical and educational settings so there is a growing need for \textbf{explainable Artificial Intelligence} that ensure the decision-making processes are transparent and understandable. This would be especially important in contexts like ADHD diagnosis, where require clarity about model predictions Papers~([\citealp{ref10}], [\citealp{ref19}]). \\ 

\textbullet \textbf{Larger Datasets and Personalized Approaches:} Expanding datasets to include a wide range of individuals and environmental contexts would help improve model generalization. Also, using personalized methods that adjust to how each person thinks and processes information could make attention monitoring systems work much better and smoother Papers~([\citealp{ref5}], [\citealp{ref9}]). \\ 

\textbullet \textbf{Integration with Educational Tools:} Real-time feedback could be provided to learners and instructors by Integrating Artificial Intelligence based attention monitoring systems with \textbf{e-Learning platforms} and \textbf{virtual reality tools}. This could help create personalized support that helps student engagement and improves learning results Papers~([\citealp{ref8}], [\citealp{ref7}]). \\ \\


\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{bar.png}
\caption{Future Directions Suggested by Papers}
\end{figure}

\begin{table}[H]
\centering
\caption{Future Research Directions Identified in Reviewed Papers}
\rowcolors{2}{lightgray}{white}
\begin{tabular}{|p{0.55\textwidth}|p{0.22\textwidth}|p{0.20\textwidth}|}
\hline
\textbf{Future Direction Suggested} & \textbf{No. of Papers Addressing This Suggestion} & \textbf{Papers} \\
\hline
Real-time systems and processing & 4 & Papers~([\citealp{ref1}], [\citealp{ref3}], [\citealp{ref4}], [\citealp{ref18}]) \\
\hline
Multimodal data integration & 5 & Papers~([\citealp{ref2}], [\citealp{ref5}], [\citealp{ref8}], [\citealp{ref11}], [\citealp{ref15}]) \\
\hline
Larger, more diverse datasets & 4 & Papers~([\citealp{ref2}], [\citealp{ref3}], [\citealp{ref5}], [\citealp{ref11}]) \\
\hline
Personalized models & 3 & Papers~([\citealp{ref2}], [\citealp{ref5}], [\citealp{ref3}]) \\
\hline
Improved accuracy and robustness of models & 4 & Papers~([\citealp{ref5}], [\citealp{ref6}], [\citealp{ref9}], [\citealp{ref17}]) \\
\hline
Use of new technologies (e.g., VR, AI, Explainable AI) & 4 & Papers~([\citealp{ref1}], [\citealp{ref6}], [\citealp{ref16}], [\citealp{ref5}]) \\
\hline
Integration with educational tools or real-life tasks & 3 & Papers~([\citealp{ref1}], [\citealp{ref7}], [\citealp{ref6}]) \\
\hline
Addressing privacy concerns & 2 & Papers~([\citealp{ref6}], [\citealp{ref8}]) \\
\hline
\end{tabular}
\end{table}

\section{Discussion}
In this section, we explore what the systematic literature review reveals about Artificial Intelligence powered methods for assessing attention and focus in digital age. We connect the main findings to existing research and also analyze at the strengths and weaknesses of the different approaches that were reviewed.

\subsection{ Artificial Intelligence Techniques for Assessing Attention} \\

The review shows that a wide variety of Artificial Intelligence techniques have been successfully used to assess attention in digital environments. From advanced deep learning models like \textbf{YOLOv3}, \textbf{YOLOv5}, and \textbf{LSTM}, to more traditional machine learning methods like \textbf{SVM} and \textbf{Random Forest}. Deep learning models are especially good at handling unstructured data, such as video and physiological signals, while traditional models still can work very well with structured data like EEG readings and behavioral patterns.

A noticeable portion across the papers is the move toward multimodal Artificial Intelligence systems that combine data from different sources like \textbf{EEG}, \textbf{eye-tracking}, and \textbf{facial expression} analysis. These combined approaches are proving much more effective than using just one type of data. For instance, bringing together EEG readings with facial expression or video analysis helps give a more accurate picture of attention of a person by capturing both cognitive and behavioral signals. This reflects an important agreement in the research that understanding human attention is complex and needs flexible and also multi-layered models that can adapt to different situations Papers~([\citealp{ref1}], [\citealp{ref7}], [\citealp{ref16}]).

The ability of Artificial Intelligence models to \textbf{detect shifts in attention in real-time} within educational settings is very fascinating. Technologies like \textbf{YOLOv5} and \textbf{DeepSORT} are showing great positivity in enabling the monitoring of student engagement during both in-person and online learning. These advancements are a major step forward in overcoming the challenges faced by previous attention detection systems, which often relied on intrusive equipment. 

\subsection{ Dataset Diversity and Evaluation Metrics} \\

One major takeaway from the review is the wide range of datasets used across different studies, including \textbf{EEG data}, \textbf{facial expressions}, and \textbf{eye-tracking datasets}. This variety highlights the complex nature of attention and the need for different types of data to capture perfectly in various contexts. EEG data, in particular, has been widely used in studies related to cognitive load and \textbf{ADHD}, with models like \textbf{SVM} and \textbf{Random Forest} showing strong accuracy in identifying attention deficits Papers~([\citealp{ref11}], [\citealp{ref19}]). However, a major challenge remains the small sample sizes of these datasets that raise a concern about how well the findings can be generalized to larger populations.

Most of the studies evaluated model performance using metrics like \textbf{accuracy}, \textbf{precision}, and \textbf{AUC}. \textbf{AUC} especially important for models focused on diagnosing \textbf{ADHD} Papers~([\citealp{ref11}], [\citealp{ref19}]). However, the heavy reliance on accuracy as the main performance measure brings up concerns, especially when dealing with imbalanced datasets where attention states (such as high vs. low attention) are not equally represented. To improve the evaluation of models, future research should consider using more comprehensive metrics like \textbf{F1-score} or \textbf{balanced accuracy}. These metrics offer a more close understanding of model performance, especially in real-world situations where datasets are often imbalanced Papers~([\citealp{ref9}], [\citealp{ref13}]).

\subsection{ Effectiveness of Machine Learning Models} \\

The studies reviewed show that machine learning models, especially deep learning approaches can be highly effective in detecting attention shifts, with some even achieving \textbf{impressive accuracy} in real-time applications Papers~([\citealp{ref1}], [\citealp{ref8}]). Model performance often depends on the type of data being used. For example, \textbf{facial expression recognition} and \textbf{eye-tracking techniques} tend to be more accurate when evaluating attention during visual tasks, while \textbf{EEG-based models} are better for identifying cognitive load and attention deficits Papers~([\citealp{ref3}], [\citealp{ref16}]). A promising step emerging from this research is the use of hybrid models that combine multiple data sources. These models can address the limitations of individual methods and offer a more complete picture of the attention of a person by integrating different types of input.

\textbf{EEG-based models} have shown strong potential in clinical settings, especially for diagnosing \textbf{ADHD}. Studies using models like \textbf{SVM} and \textbf{Random Forest} achieved remarkably high accuracy, some reaching \textbf{up to 99.58\pct} in identifying \textbf{ADHD-related attention patterns} Papers~([\citealp{ref11}], [\citealp{ref19}]). These results suggest that Artificial Intelligence could play a vital role in streamlining and improving the diagnostic process, offering quicker, smarter and potentially more reliable alternatives to traditional methods. However, some challenges still need to be addressed. Issues like \textbf{data imbalance}, \textbf{overfitting}, and \textbf{differences between individual subjects} continue to limit how well these models can generalize, which creates obstacles to their broader clinical adoption Papers~([\citealp{ref3}], [\citealp{ref13}]).

\subsection{ Challenges and Limitations} \\ 

Despite promising advancements, Artificial Intelligence powered attention assessment still faces some ongoing challenges. One of the most significant is the \textbf{limited sample size of many datasets}, especially those focused on clinical conditions like \textbf{ADHD} Papers~([\citealp{ref11}], [\citealp{ref13}]). Small datasets increase the risk of \textbf{overfitting}. When a model may perform well during training but struggle to deliver accurate results on new and unseen data it is called overfitting. This problem is compounded by the lack of large, high-quality datasets. Without big and more inclusive data, it is difficult to build models that are very much generalizable and effective across different populations.

\textbf{Privacy} concerns also a major challenge in the development of Artificial Intelligence based attention assessment tools. Using \textbf{biometric data} like \textbf{facial expressions}, \textbf{eye movements}, and \textbf{EEG signals} causes important ethical questions about how this sensitive information is collected, stored, and used. To build trust in these systems, it is important that they work with privacy regulations such as the GDPR. Another issue is the subjectivity of certain data sources, like self-reported attention levels or observational assessments which may not accurately reflect an individual true cognitive state Papers~([\citealp{ref5}], [\citealp{ref6}]).

\textbf{Accessibility} remains another key concern in the development of Artificial Intelligence based attention monitoring systems. Many current models still depend on \textbf{specialized hardware}, like \textbf{EEG headsets} and \textbf{eye-tracking devices} which can be costly and complicated to operate. This reliance on high-end equipment makes it difficult to implement, especially in low-resource environments or at a larger scale Papers~([\citealp{ref8}], [\citealp{ref14}]). To make attention monitoring technologies truly more inclusive and practical, it is necessary to find ways to reduce dependency on such hardware and develop more accessible, user-friendly solutions.

\subsection{ Future Research Directions} \\

Looking ahead, there are several exciting ways for advancing Artificial Intelligence based attention assessment. One of the promising directions is the \textbf{development of multimodal systems} that combine data from different sources, such as \textbf{EEG signals}, \textbf{facial expressions}, and \textbf{eye movements}. These systems can offer a more accurate picture of attention and also can address many of the limitations seen in single-modality approaches by integrating multiple types of input Papers~([\citealp{ref1}], [\citealp{ref7}]).

Another key focus for future research is \textbf{creating real-time monitoring systems} that can work effectively and smoothly in everyday environments like classrooms or workplaces. Such systems could deliver immediate feedback and enable personalized interventions based on attention levels of a person and ultimately supporting better learning outcomes and improved productivity Papers~([\citealp{ref6}], [\citealp{ref8}]).

\textbf{Incorporating explainable Artificial Intelligence (XAI)} techniques is becoming increasingly important for improving the transparency and trustworthiness of Artificial Intelligence driven attention monitoring systems. It is needed in especially in clinical contexts, where decisions can have significant consequences for an individual health and well-being Papers~([\citealp{ref10}], [\citealp{ref19}])

Additionally, future research should prioritize expanding datasets to include more diverse populations and real-world environments. Larger and more representative data will help build models that are not only more robust but also more generalizable across different population, demographics and use cases Papers~([\citealp{ref9}], [\citealp{ref16}]). This step is essential for developing attention assessment tools that are fair, reliable, and effective in a wider range of settings and sectors.

\section{Conclusion}
In conclusion, Artificial Intelligence powered approaches to attention assessment have shown remarkable progress, especially in educational and clinical settings. By using advancements of machine learning techniques alongside varied data sources, such as \textbf{EEG signals}, \textbf{facial expressions}, and \textbf{eye-tracking} researchers have been able to effectively detect attention shifts and also can support the diagnosis of attention-related disorders.
Despite these advancements, several challenges occur. \textbf{Limited sample sizes}, \textbf{concerns around data privacy} and \textbf{the dependence on specialized hardware} continue to effect broader adoption. To move forward, future research should prioritize building more generalizable models, developing larger and more diverse datasets, and advancing multimodal systems. These steps will make Artificial Intelligence powered attention assessment tools more accurate, ethical, and applicable in real-world scenarios. \\ 

\section{References}
\vspace{-2em}
\renewcommand{\refname}{} % Removes the automatic "References" heading
\begin{thebibliography}{99}

\bibitem{ref1} D. F. Terraza Arciniegas, M. Amaya, A. Piedrahita Carvajal, P. A. Rodriguez-Marin, L. Duque-Muñoz, and J. D. Martinez-Vargas, "Students' Attention Monitoring System in Learning Environments based on Artificial Intelligence," IEEE Latin America Transactions, vol. 20, no. 1, pp. 126–132, Jan. 2022, doi: 10.1109/TLA.2022.9662181.

\bibitem{ref2} P. Chakraborty, M. A. Yousuf, and S. Rahman, "Predicting Level of Visual Focus of Human’s Attention Using Machine Learning Approaches," in Proc. Int. Conf. Trends Comput. Cogn. Eng., Springer, Singapore, 2021, vol. 1309, doi: 10.1007/978-981-33-4673-4\_56.

\bibitem{ref3} A. Saha, V. Minz, S. Bonela, S. R. Sreeja, R. Chowdhury, and D. Samanta, "Classification of EEG Signals for Cognitive Load Estimation Using Deep Learning Architectures," in Intelligent Human Computer Interaction (IHCI 2018), vol. 11278, Springer, Cham, 2018, doi: 10.1007/978-3-030-04021-5\_6.

\bibitem{ref4} I. Hassan, M. Zolezzi, H. Khalil, R. M. Al Saady, S. Pedersen, and M. E. H. Chowdhury, "Cognitive Load Estimation Using a Hybrid Cluster-Based Unsupervised Machine Learning Technique," IEEE Access, vol. 12, pp. 118785–118801, 2024, doi: 10.1109/ACCESS.2024.3428691.

\bibitem{ref5} V. Tsakou and A. Drigas, "Early Detection of Preschool Children with ADHD and the role of mobile Apps and AI," Technium Social Sciences Journal, vol. 30, no. 1, pp. 127–137, 2022, doi: 10.47577/tssj.v30i1.6266.

\bibitem{ref6} Z. Abdelhadi, M. Naseif, W. Alhejali, and A. Elhayek, "TeacherEye: An AI-Powered System for Monitoring Student Engagement in Online Education," in Proc. 22nd Int. Learn. Technol. Conf. (L&T), Jeddah, Saudi Arabia, 2025, pp. 25–30, doi: 10.1109/LT64002.2025.10940905.

\bibitem{ref7} Q. Deng and Z. Wu, "Untitled," IOP Conf. Ser.: Earth Environ. Sci., vol. 199, p. 032042, 2018, doi: 10.1088/1755-1315/199/3/032042.

\bibitem{ref8} Z. Trabelsi, F. Alnajjar, M. M. A. Parambil, M. Gochoo, and L. Ali, "Real-Time Attention Monitoring System for Classroom: A Deep Learning Approach for Student’s Behavior Recognition," Big Data Cogn. Comput., vol. 7, p. 48, 2023, doi: 10.3390/bdcc7010048.

\bibitem{ref9} N. Alruwais and M. Zakariah, "Student-Engagement Detection in Classroom Using Machine Learning Algorithm," Electronics, vol. 12, p. 731, 2023, doi: 10.3390/electronics12030731.

\bibitem{ref10} S. S. Abdul Hamid, N. Admodisastro, N. Manshor, A. Kamaruddin, and A. A. A. Ghani, "Dyslexia Adaptive Learning Model: Student Engagement Prediction Using Machine Learning Approach," in Recent Advances on Soft Computing and Data Mining (SCDM 2018), vol. 700, Springer, Cham, 2018, doi: 10.1007/978-3-319-72550-5\_36.

\bibitem{ref11} C. Nash, R. Nair, and S. M. Naqvi, "Machine Learning in ADHD and Depression Mental Health Diagnosis: A Survey," IEEE Access, vol. 11, pp. 86297–86317, 2023, doi: 10.1109/ACCESS.2023.3304236.

\bibitem{ref12} M. Cao, E. Martin, and X. Li, "Machine learning in attention-deficit/hyperactivity disorder: new approaches toward understanding the neural mechanisms," Transl Psychiatry, vol. 13, p. 236, 2023, doi: 10.1038/s41398-023-02536-w.

\bibitem{ref13} T. Chen, G. Antoniou, M. Adamou, I. Tachmazidis, and P. Su, "Automatic Diagnosis of Attention Deficit Hyperactivity Disorder Using Machine Learning," Applied Artificial Intelligence, vol. 35, no. 9, pp. 657–669, 2021, doi: 10.1080/08839514.2021.1933761.

\bibitem{ref14} M. D. Heller, K. Roots, S. Srivastava, J. Schumann, J. Srivastava, and T. S. Hale, "A Machine Learning-Based Analysis of Game Data for Attention Deficit Hyperactivity Disorder Assessment," Games for Health Journal, vol. 2, no. 5, pp. 291–298, 2013, doi: 10.1089/g4h.2013.0058.

\bibitem{ref15} D. Andrikopoulos, G. Vassiliou, P. Fatouros et al., "Machine learning-enabled detection of attention-deficit/hyperactivity disorder with multimodal physiological data: a case-control study," BMC Psychiatry, vol. 24, p. 547, 2024, doi: 10.1186/s12888-024-05987-7.

\bibitem{ref16} M. E. Minissi, I. A. Chicchi Giglioli, F. Mantovani et al., "Assessment of the Autism Spectrum Disorder Based on Machine Learning and Social Visual Attention: A Systematic Review," J Autism Dev Disord, vol. 52, pp. 2187–2202, 2022, doi: 10.1007/s10803-021-05106-5.

\bibitem{ref17} L. Caselles-Pina, A. Quesada-López, A. Sújar, E. M. Garzón Hernández, and D. Delgado-Gómez, "A systematic review on the application of machine learning models in psychometric questionnaires for the diagnosis of attention deficit hyperactivity disorder," Eur. J. Neurosci., vol. 60, no. 3, pp. 4115–4127, 2024, doi: 10.1111/ejn.16288.

\bibitem{ref18} Ö. Kasim, "Identification of attention deficit hyperactivity disorder with deep learning model," Phys. Eng. Sci. Med., vol. 46, pp. 1081–1090, 2023, doi: 10.1007/s13246-023-01275-y.

\bibitem{ref19} M. de O. Meira, A. M. de P. Canuto, B. M. de Carvalho, and R. L. C. Jales, "Comparison of Machine Learning predictive methods to diagnose the Attention Deficit/Hyperactivity Disorder levels using SPECT," Research, Society and Development, vol. 11, no. 8, p. e54811831258, 2022, doi: 10.33448/rsd-v11i8.31258.

\end{thebibliography}

\end{document}
