# Systematic Literature Review (SLR) Summary: AI-Powered Attention Assessment

| Paper Title                                                                       | AI Techniques Used                        | Dataset Description                                                                                                                                           | Evaluation Metrics               | Reported Accuracy / Effectiveness                                         | Key Challenges Noted                                                                                  | Future Directions Suggested                                                                                       |
|-----------------------------------------------------------------------------------|-------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|
| *Real-Time Attention Monitoring System for Classroom: A Deep Learning Approach*   | YOLOv5 (v5n, v5s, v5m, v5l, v5x), DeepSORT | - **Action Dataset**: 5,701 images (self-collected + web-sourced) labeled into 9 behaviors. <br> - **Emotion Dataset**: 35,000 images (AffectNet + masked variants). | Precision, Recall, mAP@0.5, F1-score | - **Action Detection**: 76% mAP@0.5 <br> - **Emotion Recognition**: 87.7% mAP@0.5 | - Small dataset size <br> - Limited real-world validation <br> - Privacy concerns <br> - Computational cost | - Integration with social robots <br> - Larger-scale trials <br> - Multi-modal fusion (EEG + vision) <br> - Explainable AI (XAI) |


| Paper Title | AI Techniques Used | Dataset Description | Evaluation Metrics | Reported Accuracy / Effectiveness | Key Challenges Noted | Future Directions Suggested |
|-------------|--------------------|---------------------|--------------------|-----------------------------------|----------------------|-----------------------------|
| *Student-Engagement Detection in Classroom Using Machine Learning Algorithm* | - CATBoost<br>- XGBoost<br>- LightGBM<br>- Random Forest<br>- Multilayer Perceptron | Open University Learning Analytics Dataset (OULAD):<br>- 32,593 student records<br>- 13 features (demographics, VLE interactions, etc.)<br>- Binary engagement classification (high/low) | - Accuracy<br>- Precision<br>- Recall<br>- F1-score<br>- AUC-ROC<br>- Log Loss | - CATBoost: 92.23% accuracy, 94.64% precision, 93.3% recall, 0.9626 AUC<br>- LightGBM: 92.22% accuracy, 94.4% precision<br>- XGBoost: 92.1% accuracy<br>- Outperformed AISAR model (91% precision) | - Class imbalance (72% low engagement)<br>- Limited interpretability of complex models<br>- Generalizability across different learning environments<br>- Privacy concerns with student data | - Incorporate additional data sources (learning preferences, material characteristics)<br>- Investigate dropout-engagement correlation<br>- Adaptive learning interventions<br>- Explainable AI for model transparency |
